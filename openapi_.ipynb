{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinheechan/Text_summarization_Translation/blob/main/openapi_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2f327e7",
      "metadata": {
        "id": "e2f327e7"
      },
      "source": [
        "# OpenAPI를 이용한 논문, 기사, 글 요약 및 번역\n",
        "\n",
        "### Reference\n",
        "\n",
        "```\n",
        "이제현, 유시현, 김창기, 김현구, \"Open API를 활용한 고속 논문 분석\",\n",
        "실용인공지능학회지 vol.1 p.9, 2022\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df051431",
      "metadata": {
        "id": "df051431"
      },
      "source": [
        "## Get - API key\n",
        "\n",
        "- Rapid_API Adress : https://rapidapi.com/developer/new\n",
        "- RapidAPI는 웹 API를 탐색하고 사용할 수 있도록 도와주는 플랫폼입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b204963a",
      "metadata": {
        "id": "b204963a"
      },
      "outputs": [],
      "source": [
        "rapidapi_key = '569afc919amsh345e96c64b0a032p1fc949jsnb6f0a0d5351b'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Model : TLDRThis"
      ],
      "metadata": {
        "id": "XGdKD-Q9rRed"
      },
      "id": "XGdKD-Q9rRed"
    },
    {
      "cell_type": "markdown",
      "id": "f74b1efd",
      "metadata": {
        "id": "f74b1efd"
      },
      "source": [
        "### Human-like Article Summarization\n",
        "\n",
        "텍스트를 요약해주는 인공지능 모델 4개의 성능을 테스트합니다.\n",
        "<br /><br />\n",
        "\n",
        "- Human-like Article Summarization\n",
        "\n",
        "- Extractive Article Summarization\n",
        "\n",
        "- Human-like Text Summarization\n",
        "\n",
        "- Extractive Text Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 요약의 종류\n",
        "\n",
        "1. Human-like summarization\n",
        "\n",
        "> Abstractive summarization(생성 요약)은 기존 Input text를 그대로 인용하지 않고,   \n",
        "기존의 내용을 새롭게 re-phrasing 하여 Summary를 생성하는 요약 모델입니다.\n",
        "\n",
        "2. Extractive summarization\n",
        "\n",
        "> 반면에 Extractive summarization(추출 요약)은 기존 Input text에 존재하는  \n",
        " 중요한 단어를 그대로 사용하여 Summary를 생성하는 요약 모델입니다."
      ],
      "metadata": {
        "id": "otDvc96ysvn1"
      },
      "id": "otDvc96ysvn1"
    },
    {
      "cell_type": "markdown",
      "id": "61573ca4",
      "metadata": {
        "id": "61573ca4"
      },
      "source": [
        "## 3. Dataset : 예시 논문\n",
        "\n",
        "본 코드 테스트를 위한 글로 아래 논문을 활용합니다.\n",
        "\n",
        "- 페이지 : https://arxiv.org/abs/1706.03762\n",
        "- 본문(pdf) : https://arxiv.org/pdf/1706.03762.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Setting"
      ],
      "metadata": {
        "id": "hMzvelfVs7ee"
      },
      "id": "hMzvelfVs7ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69898271",
      "metadata": {
        "id": "69898271"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f600ad29",
      "metadata": {
        "id": "f600ad29"
      },
      "source": [
        "## 5. Text_Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "본 코드는 Web에서 요청한 자료이므로 pdf 가 아니라 웹 이므로 html 코드로 반환됩니다.\n",
        "\n",
        "또한 가장 하단에 summay 텍스트도 함께 첨부됩니다."
      ],
      "metadata": {
        "id": "VVs1Z5kRLPb2"
      },
      "id": "VVs1Z5kRLPb2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Human-like Article Summarization 모델의 URL 등록\n",
        "url = 'https://tldrthis.p.rapidapi.com/v1/model/abstractive/summarize-url/'\n",
        "\n",
        "# 테스트 논문 등록 및 요약글 설정\n",
        "payload = {\n",
        "    \"url\": \"https://proceedings.mlr.press/v97/tan19a.html?ref=jina-ai-gmbh.ghost.io\",\n",
        "    \"min_length\": 100,\n",
        "    \"max_length\": 300,\n",
        "    \"is_detailed\": False\n",
        "}\n",
        "\n",
        "# 설명서 양식 참고\n",
        "headers = {\n",
        "    \"content-type\": \"application/json\",\n",
        "    \"X-RapidAPI-Key\": rapidapi_key,\n",
        "    \"X-RapidAPI-Host\": \"tldrthis.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
        "\n",
        "pprint(response.json())"
      ],
      "metadata": {
        "id": "WcKTwNmbH7bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c64daeb-59b8-4723-d2e1-3524c561f6db"
      },
      "id": "WcKTwNmbH7bf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'article_abstract': None,\n",
            " 'article_authors': ['Mingxing Tan', 'Quoc Le'],\n",
            " 'article_html': '<div><p class=\"bibbuttontext column\">\\n'\n",
            "                 '    BibTeX\\n'\n",
            "                 '  </p><p class=\"codebox\">\\n'\n",
            "                 '    <code class=\"citecode\" id=\"bibtex\">\\n'\n",
            "                 '@InProceedings{pmlr-v97-tan19a,\\n'\n",
            "                 '  title = \\t {{E}fficient{N}et: Rethinking Model Scaling for '\n",
            "                 'Convolutional Neural Networks},\\n'\n",
            "                 '  author =       {Tan, Mingxing and Le, Quoc},\\n'\n",
            "                 '  booktitle = \\t {Proceedings of the 36th International '\n",
            "                 'Conference on Machine Learning},\\n'\n",
            "                 '  pages = \\t {6105--6114},\\n'\n",
            "                 '  year = \\t {2019},\\n'\n",
            "                 '  editor = \\t {Chaudhuri, Kamalika and Salakhutdinov, '\n",
            "                 'Ruslan},\\n'\n",
            "                 '  volume = \\t {97},\\n'\n",
            "                 '  series = \\t {Proceedings of Machine Learning Research},\\n'\n",
            "                 '  month = \\t {09--15 Jun},\\n'\n",
            "                 '  publisher =    {PMLR},\\n'\n",
            "                 '  pdf = \\t '\n",
            "                 '{http://proceedings.mlr.press/v97/tan19a/tan19a.pdf},\\n'\n",
            "                 '  url = \\t {https://proceedings.mlr.press/v97/tan19a.html},\\n'\n",
            "                 '  abstract = \\t {Convolutional Neural Networks (ConvNets) '\n",
            "                 'are commonly developed at a fixed resource budget, and then '\n",
            "                 'scaled up for better accuracy if more resources are given. '\n",
            "                 'In this paper, we systematically study model scaling and '\n",
            "                 'identify that carefully balancing network depth, width, and '\n",
            "                 'resolution can lead to better performance. Based on this '\n",
            "                 'observation, we propose a new scaling method that uniformly '\n",
            "                 'scales all dimensions of depth/width/resolution using a '\n",
            "                 'simple yet highly effective compound coefficient. We '\n",
            "                 'demonstrate the effectiveness of this method on MobileNets '\n",
            "                 'and ResNet. To go even further, we use neural architecture '\n",
            "                 'search to design a new baseline network and scale it up to '\n",
            "                 'obtain a family of models, called EfficientNets, which '\n",
            "                 'achieve much better accuracy and efficiency than previous '\n",
            "                 'ConvNets. In particular, our EfficientNet-B7 achieves '\n",
            "                 'stateof-the-art 84.4% top-1 / 97.1% top-5 accuracy on '\n",
            "                 'ImageNet, while being 8.4x smaller and 6.1x faster on '\n",
            "                 'inference than the best existing ConvNet (Huang et al., '\n",
            "                 '2018). Our EfficientNets also transfer well and achieve '\n",
            "                 'state-of-the-art accuracy on CIFAR-100 (91.7%), Flower '\n",
            "                 '(98.8%), and 3 other transfer learning datasets, with an '\n",
            "                 'order of magnitude fewer parameters.}\\n'\n",
            "                 '}\\n'\n",
            "                 '</code>\\n'\n",
            "                 '  </p>\\n'\n",
            "                 '  \\n'\n",
            "                 '  \\n'\n",
            "                 '  </div>',\n",
            " 'article_image': 'https://proceedings.mlr.press/v97/assets/images/logo-pmlr.png',\n",
            " 'article_pub_date': 'May 24, 2019',\n",
            " 'article_text': 'BibTeX\\n'\n",
            "                 '\\n'\n",
            "                 '@InProceedings{pmlr-v97-tan19a, title = {{E}fficient{N}et: '\n",
            "                 'Rethinking Model Scaling for Convolutional Neural Networks}, '\n",
            "                 'author = {Tan, Mingxing and Le, Quoc}, booktitle = '\n",
            "                 '{Proceedings of the 36th International Conference on Machine '\n",
            "                 'Learning}, pages = {6105--6114}, year = {2019}, editor = '\n",
            "                 '{Chaudhuri, Kamalika and Salakhutdinov, Ruslan}, volume = '\n",
            "                 '{97}, series = {Proceedings of Machine Learning Research}, '\n",
            "                 'month = {09--15 Jun}, publisher = {PMLR}, pdf = '\n",
            "                 '{http://proceedings.mlr.press/v97/tan19a/tan19a.pdf}, url = '\n",
            "                 '{https://proceedings.mlr.press/v97/tan19a.html}, abstract = '\n",
            "                 '{Convolutional Neural Networks (ConvNets) are commonly '\n",
            "                 'developed at a fixed resource budget, and then scaled up for '\n",
            "                 'better accuracy if more resources are given. In this paper, '\n",
            "                 'we systematically study model scaling and identify that '\n",
            "                 'carefully balancing network depth, width, and resolution can '\n",
            "                 'lead to better performance. Based on this observation, we '\n",
            "                 'propose a new scaling method that uniformly scales all '\n",
            "                 'dimensions of depth/width/resolution using a simple yet '\n",
            "                 'highly effective compound coefficient. We demonstrate the '\n",
            "                 'effectiveness of this method on MobileNets and ResNet. To go '\n",
            "                 'even further, we use neural architecture search to design a '\n",
            "                 'new baseline network and scale it up to obtain a family of '\n",
            "                 'models, called EfficientNets, which achieve much better '\n",
            "                 'accuracy and efficiency than previous ConvNets. In '\n",
            "                 'particular, our EfficientNet-B7 achieves stateof-the-art '\n",
            "                 '84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being '\n",
            "                 '8.4x smaller and 6.1x faster on inference than the best '\n",
            "                 'existing ConvNet (Huang et al., 2018). Our EfficientNets '\n",
            "                 'also transfer well and achieve state-of-the-art accuracy on '\n",
            "                 'CIFAR-100 (91.7%), Flower (98.8%), and 3 other transfer '\n",
            "                 'learning datasets, with an order of magnitude fewer '\n",
            "                 'parameters.} }\\n'\n",
            "                 '\\n'\n",
            "                 'Copy to Clipboard\\n'\n",
            "                 '\\n'\n",
            "                 'Download',\n",
            " 'article_title': 'EfficientNet: Rethinking Model Scaling for Convolutional '\n",
            "                  'Neural Networks',\n",
            " 'article_url': 'https://proceedings.mlr.press/v97/tan19a.html?ref=jina-ai-gmbh.ghost.io',\n",
            " 'summary': ['Convolutional Neural Networks (ConvNets) are commonly developed '\n",
            "             'at a fixed resource budget, and then scaled up for better '\n",
            "             'accuracy if more resources are given. Based on this observation, '\n",
            "             'we propose a new scaling method that uniformly scales all '\n",
            "             'dimensions of depth/width/resolution using a simple yet highly '\n",
            "             'effective compound coefficient. We demonstrate the effectiveness '\n",
            "             'of this method on MobileNets and ResNet.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HTTP 응답에서 'summary' 키 값을 출력합니다."
      ],
      "metadata": {
        "id": "MkYJTnLuK9ba"
      },
      "id": "MkYJTnLuK9ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9911dfa",
      "metadata": {
        "id": "a9911dfa",
        "outputId": "872dd7be-d707-4b83-e55c-8aa6cbcaff21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are given. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on MobileNets and ResNet.\n"
          ]
        }
      ],
      "source": [
        "summary = response.json()['summary'][0].strip()\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Translation\n",
        "\n",
        "### 6.1 Google Transe API"
      ],
      "metadata": {
        "id": "CK5FMBo8q1-t"
      },
      "id": "CK5FMBo8q1-t"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- googletranse : api 불필요하며 구글 번역 수준의 성능을 가지고 있습니다."
      ],
      "metadata": {
        "id": "LWpRCcuw5DbR"
      },
      "id": "LWpRCcuw5DbR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 구글 번역 api 래퍼런스 및 코드 메뉴얼은 https://www.dinolabs.ai/386 링크를 참고하였습니다."
      ],
      "metadata": {
        "id": "NvGoZzZX5bym"
      },
      "id": "NvGoZzZX5bym"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzwr1xBDkuG3",
        "outputId": "87348494-5a4c-4c87-9424-aa222321cca6"
      },
      "id": "Dzwr1xBDkuG3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans==3.1.0a0 in /usr/local/lib/python3.10/dist-packages (3.1.0a0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.2.2)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2024.4.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "import json\n",
        "\n",
        "def translate_text(text, target_language='ko'):\n",
        "    translator = Translator()\n",
        "    translated_sentences = []\n",
        "    for sentence in text:\n",
        "        translated_sentence = translator.translate(sentence, dest=target_language)\n",
        "        translated_sentences.append(translated_sentence.text)\n",
        "    return translated_sentences\n",
        "\n",
        "# 응답받은 텍스트 디코딩\n",
        "# 문자열하고 json은 결은 같지만 형태는 달라 변환이 필요하다.\n",
        "response_text = response.text\n",
        "response_json = json.loads(response_text)\n",
        "\n",
        "# 번역할 텍스트 추출\n",
        "text_to_translate = response_json.get('summary', '')\n",
        "\n",
        "# 번역된 텍스트\n",
        "translated_text = translate_text(text_to_translate)\n",
        "\n",
        "print(\"번역된 텍스트:\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O73SLFEXkrmi",
        "outputId": "398d4cbc-b330-42e5-9312-585d7272a535"
      },
      "id": "O73SLFEXkrmi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "번역된 텍스트: ['ConvNet(Convolutional Neural Network)은 일반적으로 고정된 리소스 예산으로 개발된 다음 더 많은 리소스가 제공되면 정확도를 높이기 위해 확장됩니다. 이러한 관찰을 바탕으로 우리는 간단하지만 매우 효과적인 복합 계수를 사용하여 깊이/너비/해상도의 모든 차원을 균일하게 스케일링하는 새로운 스케일링 방법을 제안합니다. 우리는 MobileNets 및 ResNet에서 이 방법의 효율성을 보여줍니다.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df0b8837",
      "metadata": {
        "id": "df0b8837"
      },
      "source": [
        "## 함수화"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞선 번역 및 실행 과정이 이슈 없이 실행됨을 확인하였으며\n",
        "\n",
        "본 프로젝트를 진행하기 위한 함수 코드를 제작하여 테스트에 활용합니다."
      ],
      "metadata": {
        "id": "Wz6K9EH8o4iR"
      },
      "id": "Wz6K9EH8o4iR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef2e310",
      "metadata": {
        "id": "3ef2e310"
      },
      "outputs": [],
      "source": [
        "# Rapid API URL\n",
        "url = 'https://tldrthis.p.rapidapi.com/v1/model/abstractive/summarize-url/'\n",
        "\n",
        "# 요약 기능\n",
        "def summarize_and_translate(article_url, min_length=100, max_length=300, target_language='ko'):\n",
        "\n",
        "    payload = {\n",
        "    \"url\": \"https://proceedings.mlr.press/v97/tan19a.html?ref=jina-ai-gmbh.ghost.io\",\n",
        "    \"min_length\": 100,\n",
        "    \"max_length\": 300,\n",
        "    \"is_detailed\": False\n",
        "    }\n",
        "\n",
        "    # 설명서 양식 참고\n",
        "    headers = {\n",
        "        \"content-type\": \"application/json\",\n",
        "        \"X-RapidAPI-Key\": rapidapi_key,\n",
        "        \"X-RapidAPI-Host\": \"tldrthis.p.rapidapi.com\"\n",
        "    }\n",
        "\n",
        "    response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
        "    return pprint(response.json())\n",
        "\n",
        "# 번역 기능\n",
        "def translate_text(text, target_language='ko'):\n",
        "    translator = Translator()\n",
        "    translated_sentences = []\n",
        "    for sentence in text:\n",
        "        translated_sentence = translator.translate(sentence, dest=target_language)\n",
        "        translated_sentences.append(translated_sentence.text)\n",
        "    return translated_sentences\n",
        "\n",
        "    response_text = response.text\n",
        "    response_json = json.loads(response_text)\n",
        "\n",
        "    # 번역할 텍스트 추출\n",
        "    text_to_translate = response_json.get('summary', '')\n",
        "\n",
        "    return text_to_translate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Result"
      ],
      "metadata": {
        "id": "f1AKS-E2miNB"
      },
      "id": "f1AKS-E2miNB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1 Human-like Article Summarization"
      ],
      "metadata": {
        "id": "KNVUHnokpJe5"
      },
      "id": "KNVUHnokpJe5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88afea5a",
      "metadata": {
        "id": "88afea5a"
      },
      "outputs": [],
      "source": [
        "summary_input = summarize_and_translate(\"https://www.bbc.com/news/world-australia-68720242\", 50, 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translated_text = translate_text(text_to_translate)\n",
        "\n",
        "pprint(translated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PihvsbEckjq7",
        "outputId": "d3738673-f3a3-46f6-944d-f1ad8b33f325"
      },
      "id": "PihvsbEckjq7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ConvNet(Convolutional Neural Network)은 일반적으로 고정된 리소스 예산으로 개발된 다음 더 많은 리소스가 '\n",
            " '제공되면 정확도를 높이기 위해 확장됩니다. 이러한 관찰을 바탕으로 우리는 간단하지만 매우 효과적인 복합 계수를 사용하여 '\n",
            " '깊이/너비/해상도의 모든 차원을 균일하게 스케일링하는 새로운 스케일링 방법을 제안합니다. 우리는 MobileNets 및 ResNet에서 '\n",
            " '이 방법의 효율성을 보여줍니다.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.2 Extractive Article Summarization"
      ],
      "metadata": {
        "id": "XZQRTaCspQtU"
      },
      "id": "XZQRTaCspQtU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.3 Human-like Text Summarization"
      ],
      "metadata": {
        "id": "xkk0GhStpQ33"
      },
      "id": "xkk0GhStpQ33"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.4 Extractive Text Summarization"
      ],
      "metadata": {
        "id": "jGnNUrB9pRAY"
      },
      "id": "jGnNUrB9pRAY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "ㅇㅇㅇㅇㅇ"
      ],
      "metadata": {
        "id": "PlschNylqTAZ"
      },
      "id": "PlschNylqTAZ"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}